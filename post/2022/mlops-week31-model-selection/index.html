<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Study notes: MLops Week 3-1 Machine Learning pipeline - walking in the woods</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="fermion"><meta name=description content="Week 3-1 of the AWS MLops: ML steps, pipeline, and AWS SageMaker
"><meta name=keywords content="Hugo,theme,even"><meta name=generator content="Hugo 0.119.0 with theme even"><link rel=canonical href=http://chang48.github.io/post/2022/mlops-week31-model-selection/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link href=/sass/main.min.f92fd13721ddf72129410fd8250e73152cc6f2438082b6c0208dc24ee7c13fc4.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin=anonymous><meta property="og:title" content="Study notes: MLops Week 3-1 Machine Learning pipeline"><meta property="og:description" content="Week 3-1 of the AWS MLops: ML steps, pipeline, and AWS SageMaker"><meta property="og:type" content="article"><meta property="og:url" content="http://chang48.github.io/post/2022/mlops-week31-model-selection/"><meta property="og:image" content="http://chang48.github.io/post/2022/mlops-week31-model-selection/feature-selection-embed.png"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-03-20T14:33:07-07:00"><meta property="article:modified_time" content="2022-03-20T14:33:07-07:00"><meta itemprop=name content="Study notes: MLops Week 3-1 Machine Learning pipeline"><meta itemprop=description content="Week 3-1 of the AWS MLops: ML steps, pipeline, and AWS SageMaker"><meta itemprop=datePublished content="2022-03-20T14:33:07-07:00"><meta itemprop=dateModified content="2022-03-20T14:33:07-07:00"><meta itemprop=wordCount content="835"><meta itemprop=image content="http://chang48.github.io/post/2022/mlops-week31-model-selection/feature-selection-embed.png"><meta itemprop=keywords content="MLops,data science,"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://chang48.github.io/post/2022/mlops-week31-model-selection/feature-selection-embed.png"><meta name=twitter:title content="Study notes: MLops Week 3-1 Machine Learning pipeline"><meta name=twitter:description content="Week 3-1 of the AWS MLops: ML steps, pipeline, and AWS SageMaker"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>walking in the woods</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/><li class=mobile-menu-item>Home</li></a><a href=/post/><li class=mobile-menu-item>Archives</li></a><a href=/tags/><li class=mobile-menu-item>Tags</li></a><a href=/categories/><li class=mobile-menu-item>Categories</li></a><a href=/about/><li class=mobile-menu-item>About</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>walking in the woods</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/>Home</a></li><li class=menu-item><a class=menu-item-link href=/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=/about/>About</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>Study notes: MLops Week 3-1 Machine Learning pipeline</h1><div class=post-meta><span class=post-time>2022-03-20</span><div class=post-category><a href=/categories/study-notes/>study notes</a></div></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>Contents</h2><div class="post-toc-content always-active"><nav id=TableOfContents><ul><li><ul><li><a href=#machine-learning-pipeline-and-aws-sagemaker>Machine Learning Pipeline and AWS SageMaker</a><ul><li><a href=#forming-business-problem>Forming business problem</a></li><li><a href=#collect-and-secure-data-etl>Collect and secure data, ETL</a></li><li><a href=#data-evaluation>Data evaluation</a></li><li><a href=#feature-engineering>Feature engineering</a></li><li><a href=#model-training-and-evaluation>Model training and evaluation</a></li><li><a href=#model-tuning>Model tuning</a></li></ul></li></ul></li></ul></nav></div></div><div class=post-content><p>Week 3-1 of the AWS MLops: ML steps, pipeline, and AWS SageMaker</p><h2 id=machine-learning-pipeline-and-aws-sagemaker>Machine Learning Pipeline and AWS SageMaker</h2><h3 id=forming-business-problem>Forming business problem</h3><ul><li><p>Define business objective, questions to ask:</p><ul><li>How is this task done today?</li><li>How will the business measure success?</li><li>How will the solution be used?</li><li>Do similar solutions exist?</li><li>What are the assumptions?</li><li>Who are the domain experts?</li></ul></li><li><p>Frame the business problem</p><ul><li>Is it a machine learning problem? What kind of ML problem is it? Classification or regression?</li><li>Is the problem supervised or unsupervised?</li><li>What is the target to predict?</li><li>Have access to the relevant data?</li><li>What is the minimum or baseline performance?</li><li>Would you solve the problem manually?</li><li>What is the simplest solution?</li><li>Can the success be measured?</li></ul></li></ul><h3 id=collect-and-secure-data-etl>Collect and secure data, ETL</h3><ul><li><p>Data sources</p><ul><li>Private data</li><li>Commercial data: AWS Data Exchange, AWS Marketplace, $\ldots$</li><li>Open-source data<ul><li>Kaggle</li><li>World Health Organization</li><li>US Census Bureau</li><li>National Oceanic and Atmospheric Administration</li><li>UC Irvine Machine Learning repository</li><li>AWS</li></ul></li><li>Critical question: <strong>Is you data <font color=red>representative</font></strong>?</li></ul></li><li><p>ETL with AWS Glue</p><ul><li>Runs the ETL process</li><li>Crawls data sources to create catalogs that can be queried</li><li>ML functionality</li><li>AWS Glue can glue together different datasets and emit a single endpoint that can be queried</li></ul><p><img src=aws-glue-overview.png alt="aws glue"></p></li><li><p>Data security: Access control and Data encryption</p><ul><li>Control access using AWS Identity and Access Management (IAM) policy</li><li>AWS S3 default encryption</li><li>AWS RDS encryption</li><li>AWS CloudTrail: tracks user activity and application programing interface (API) usage</li></ul></li></ul><h3 id=data-evaluation>Data evaluation</h3><ul><li>Make sure the data is in the correct format</li><li>Use descriptive statistics to gain insights into the dataset before cleaning the data<ul><li>Overall statistics<ul><li>Categorical statistics can identify frequency of values and class imbalances</li></ul></li><li>Multivariate statistics<ul><li>Scatter plot to inspect the correlation between two variables</li><li><code>pandas</code> provides <code>scatter_matrix</code> method to examine multivariate correlations</li><li>Correlation matrix and heat map</li></ul></li><li>Attribute statistics</li></ul></li></ul><h3 id=feature-engineering>Feature engineering</h3><ul><li><p>Feature extraction</p><ul><li><p>Data encoding</p><ul><li>Categorical data must be converted to a numeric scale</li><li>If data is non-ordinal, the encoded value must be non-ordinal which might need to be broken into multiple categories</li></ul></li><li><p>Data cleaning</p><ul><li>Variations in strings: text standardization</li><li>Variations in scale: scale normalization</li><li>Columns with multiple data items: parse into multiple columns</li><li>Missing data:<ul><li>Cause of missing data:<ul><li>undefined values</li><li>data collection errors</li><li>data cleaning errors</li></ul></li><li>Plan for missing data: ask the following questions first<ul><li>What were the mechanisms causing the missing data?</li><li>Are values missing at random?</li><li>Are rows or columns missing that you are not aware of?</li></ul></li><li>Standard approaches<ul><li>Dropping missing data</li><li>Imputing missing data</li></ul></li></ul></li><li>Outliers<ul><li>Finding the outliers: box plots or scatter plots for visualization</li><li>Dealing with outliers:<ul><li>Delete - e.g. outliers were created by artificial errors</li><li>Transform - reduce the variation</li><li>Impute - e.g. use mean for the outliers</li></ul></li></ul></li></ul></li></ul></li><li><p>Feature selection</p><ul><li><p>Filter method</p><ul><li>Pearson&rsquo;s correlation</li><li>Linear discriminant analysis (LDA)</li><li>Analysis of variance (ANOVA)</li><li>Chi-square $\chi^2$ analysis</li></ul></li><li><p>Wrapper method</p><ul><li>Forward selection</li><li>Backward selection</li></ul><figure><img src=feature-selection-wrapper.png alt="Wrapper method" width=320></figure></li><li><p>Embedded method</p><ul><li>Decision trees</li><li>LASSO and RIDGE</li></ul><figure><img src=feature-selection-embed.png alt="Embed method" width=400></figure></li></ul></li></ul><h3 id=model-training-and-evaluation>Model training and evaluation</h3><ul><li><p>Holdout method</p><ul><li>Split the data into training and test sets</li><li>The model is trained on the training set. Afterwards, its performance is evaluated by testing the model on the test set data which
the model has never touched.</li><li><strong>Advantage</strong>: straightforward to implement and computationally cheap because training and testing are carried out once each.</li><li><strong>Disadvantage</strong>:<ul><li>It could happen that the test set and the training set have different statistical distributions, i.e. the test set
data cannot faithfully represent the training set distribution. In this case, the validation result is likely not accurate.</li><li>If we tune the model based on a single test set, we may end up <em>overfitting the test data set</em>.</li><li>While this approach can be improved by using training, validation, and test set, the result might still depend on the way
data sets are prepared, leading to some degrees of bias.</li></ul></li></ul></li><li><p>$k$-fold cross-validation method, an evaluation method that minimizes the disadvantages of the holdout method.</p><ol><li>Divide the whole data set into training and test set.</li><li>Shuffle the training set randomly, if possible.<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup></li><li>Split the training set into $k$ non-overlapping subsets (folds) that are equally partitioned, if possible.</li><li>For each of the $k$ folds:<ul><li>Train a <em>new</em> model on the $k-1$ folds and validate using the remaining fold.</li><li>Retain the evaluation score and discard the model.</li></ul></li><li>The performance metric is obtained by averaging the $k$ evaluation scores.</li><li>The test set is used for final evaluation.</li></ol><figure><img src=cross-validation.png alt="k-fold CV" width=520></figure><ul><li><strong>To avoid data leakage, any feature engineering should be carried out separately for training and validation inside the CV loop</strong>.</li><li>Reference for <a href=https://neptune.ai/blog/cross-validation-mistakes target=_blank>practical advice on cross-validation</a>,
including imbalanced data set</li></ul></li><li><p>Evaluation</p><ul><li>Classification problems<ul><li>Confusion matrix</li><li>F1 score, the harmonic mean of precision and sensitivity</li><li>AUC-ROC</li></ul></li><li>Regression<ul><li>Mean squared error</li></ul></li></ul></li></ul><h3 id=model-tuning>Model tuning</h3><ul><li>Amazon Sagemaker offers automated hyperparamter tuning</li><li>Best practices<ul><li>Don&rsquo;t adjust every hyperparameter</li><li>Limit the range of values to what&rsquo;s most effective</li><li>Run one training job at a time instead of multiple jobs in parallel</li><li>In distributed training jobs, make sure that the objective metric that you want is the one that is reported back</li><li>With Amazon SageMaker, convert log-scaled hyperparameters to linear-scaled when possible</li></ul></li></ul><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>]: Time-series data is ordered and can&rsquo;t be shuffled.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>fermion</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>2022-03-20</span></p></div><footer class=post-footer><div class=post-tags><a href=/tags/mlops/>MLops</a>
<a href=/tags/data-science/>data science</a></div><nav class=post-nav><a class=prev href=/post/2022/mlops-week32-forecasting/><i class="iconfont icon-left"></i>
<span class="prev-text nav-default">Study notes: MLops Week 3-2 Forecasting</span>
<span class="prev-text nav-mobile">Prev</span></a>
<a class=next href=/post/2022/mlops-week2-aws-ml-data-preparation/><span class="next-text nav-default">Study notes: MLops Week 2 AWS ML Data Preparation</span>
<span class="next-text nav-mobile">Next</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div><script src=https://utteranc.es/client.js repo=chang48/chang48.github.io issue-term=pathname theme=github-light crossorigin=anonymous async></script><noscript>Please enable JavaScript to view the <a href=https://github.com/utterance>comments powered by utterances.</a></noscript></div></main><footer id=footer class=footer><div class=social-links><a href=https://github.com/chang48 class="iconfont icon-github" title=github></a>
<a href=https://www.instagram.com/justarandomwalker/ class="iconfont icon-instagram" title=instagram></a>
<a href=http://chang48.github.io/index.xml type=application/rss+xml class="iconfont icon-rss" title=rss></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span>
<span class=copyright-year>&copy;
2017 -
2023<span class=heart><i class="iconfont icon-heart"></i></span><span>fermion</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js></script>
<script type=text/javascript>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin=anonymous></script></body></html>